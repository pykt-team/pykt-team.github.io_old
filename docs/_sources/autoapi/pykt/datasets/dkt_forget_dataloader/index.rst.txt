:py:mod:`pykt.datasets.dkt_forget_dataloader`
=============================================

.. py:module:: pykt.datasets.dkt_forget_dataloader


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   pykt.datasets.dkt_forget_dataloader.DktForgetDataset




Attributes
~~~~~~~~~~

.. autoapisummary::

   pykt.datasets.dkt_forget_dataloader.ModelConf


.. py:data:: ModelConf
   

   

.. py:class:: DktForgetDataset(file_path, input_type, folds, qtest=False)

   Bases: :py:obj:`torch.utils.data.Dataset`

   An abstract class representing a :class:`Dataset`.

   All datasets that represent a map from keys to data samples should subclass
   it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a
   data sample for a given key. Subclasses could also optionally overwrite
   :meth:`__len__`, which is expected to return the size of the dataset by many
   :class:`~torch.utils.data.Sampler` implementations and the default options
   of :class:`~torch.utils.data.DataLoader`.

   .. note::
     :class:`~torch.utils.data.DataLoader` by default constructs a index
     sampler that yields integral indices.  To make it work with a map-style
     dataset with non-integral indices/keys, a custom sampler must be provided.

   .. py:method:: __len__(self)


   .. py:method:: __getitem__(self, index)


   .. py:method:: load_data(self, sequence_path, folds, pad_val=-1)


   .. py:method:: log2(self, t)


   .. py:method:: calC(self, row)



